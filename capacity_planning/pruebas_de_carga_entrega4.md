# üìä Reporte de Pruebas de Carga ‚Äì Capa Worker (SQS)

> **Proyecto:** Desarrollo de Software en la Nube  
> **Fecha de ejecuci√≥n:** 14-15 noviembre 2025  
> **Infraestructura evaluada:** Worker as√≠ncrono (Celery) detr√°s de SQS `video-app-queue`  
> **Herramienta:** Locust (`load_testing/locust_sqs/worker_sqs_locust.py`)

---

## 1. Resumen ejecutivo

- **Objetivo:** validar la capacidad de ingesti√≥n de mensajes hacia el worker v√≠a SQS y determinar el punto de saturaci√≥n antes de que la cola crezca sin control.
- **Escenarios ejecutados:** Smoke (sanidad), Ramp (b√∫squeda de saturaci√≥n) y Soak (estabilidad a tasa objetivo).
- **Resultado general:** la capa worker procesa establemente ~4 req/s con latencias altas (>25 s). En smoke y soak no hubo fallos, mientras que la rampa expuso errores 5xx cuando la API web no sostuvo el pico.
- **L√≠mite observado:** a partir de ~3.8 req/s con rampa agresiva aparecen 504/502/503 desde el backend, lo que impide sostener la carga antes de que SQS se vuelva el cuello de botella.
- **Recomendaciones clave:** desacoplar autenticaci√≥n del ciclo de prueba, incrementar capacidad del backend/API, habilitar autoescalado del worker y monitorear backlog SQS/CloudWatch en sincron√≠a con las pruebas.

---

## 2. Configuraci√≥n y supuestos

| Elemento | Detalle |
|----------|---------|
| **Script Locust** | `load_testing/locust_sqs/worker_sqs_locust.py` |
| **Acciones simuladas** | `POST /api/auth/login` + `POST /api/videos/upload` (genera mensaje SQS) |
| **Archivo de video** | `uploads/file_example_MP4_480_1_5MG.mp4` |
| **Credenciales** | Usuario de pruebas con rol est√°ndar, token por sesi√≥n |
| **Wait time** | `LOCUST_MIN_WAIT=0.02`, `LOCUST_MAX_WAIT=0.05` (override en soak) |
| **M√©tricas adicionales** | No se capturaron dashboards CloudWatch/Grafana; se inferir√° √∫nicamente con los CSV de Locust. |

---

## 3. Metodolog√≠a y escenarios

| Escenario | Prop√≥sito | Configuraci√≥n ejecutada | Duraci√≥n real | Observaciones |
|-----------|-----------|-------------------------|---------------|---------------|
| **Smoke** | Validar credenciales, path feliz y pipeline SQS con carga ligera. | `-u 10`, `-r 5`, `t=5m`, headless | 5 min | Sirvi√≥ para verificar health-check del worker |
| **Ramp** | Incrementar usuarios hasta encontrar el punto de saturaci√≥n. | `-u 200`, `-r 20`, `t=15m`, `--csv results/locust_ramp` | 15 min | Se dispararon errores 5xx desde backend |
| **Soak** | Mantener tasa objetivo (‚âà80 msg/s nominal, ~4 req/s efectivos) durante 45 min. | `-u 120`, `-r 10`, `t=45m`, `LOCUST_MIN/MAX_WAIT` agresivos | 45 min | Sin fallos, pero con alta latencia por ciclo de carga |

---

## 4. Resultados detallados

### 4.1 Consolidado de m√©tricas

| Escenario | Requests | Fallos | √âxito | Avg (ms) | p95 (ms) | Throughput (req/s) |
|-----------|----------|--------|-------|----------|----------|---------------------|
| Smoke | 1,125 | 0 | 100% | 2,610 | 4,600 | 3.75 |
| Ramp | 3,423 | 895 | 73.85% | 28,533 | 68,000 | 3.81 |
| Soak | 11,064 | 0 | 100% | 28,976 | 46,000 | 4.10 |

Fuente: CSV generados por Locust (`Smoke-results.csv`, `Ramp-results.csv`, `Soak-result.csv`).

### 4.2 Smoke ‚Äì Sanidad

- **M√©tricas principales:** 1,125 solicitudes totales, 0 fallos, latencia promedio 2.6 s, p95 4.6 s.
- **Observaciones:** autenticaci√≥n y subida de video completan en <3 s en carga baja; el worker procesa sin backlog observable.

```
```1:25:load_testing/locust_sqs/Smoke-results.csv
Requests: 1125
√âxito: 100.00%
Latencia media: 2610.34 ms
p95: 4600.00 ms
```

### 4.3 Ramp ‚Äì Punto de saturaci√≥n

- **M√©tricas principales:** 3,423 solicitudes, 26.15% de fallos, latencia media 28.5 s, p95 68 s.
- **Errores:** 504 Gateway Timeout (login), 502/503/504 en `Videos/Upload`. Los 895 fallos corresponden al backend antes de que el worker llegue a su l√≠mite real.
- **Hallazgo:** la capa web/API se convierte en el cuello de botella cuando la tasa supera ~3.8 req/s continuos; se requiere autoscaling o tuning espec√≠fico para la API.

```
```1:53:load_testing/locust_sqs/Ramp-results.csv
Requests: 3423
Fallos: 895
Latencia media: 28533.21 ms
p95: 68000.00 ms
POST Videos/Upload: Error 502/503/504
```

### 4.4 Soak ‚Äì Resistencia

- **M√©tricas principales:** 11,064 solicitudes, 0 fallos, latencia media 28.9 s, p95 46 s.
- **Comportamiento:** throughput sostenido de 4.1 req/s sin errores indica que, a tasa constante, la cola y el worker se mantienen estables aunque con latencias elevadas por el ciclo completo (autenticaci√≥n + upload + encolado).
- **Riesgo:** la latencia promedio >28 s implica que cualquier degradaci√≥n adicional (CPU, IO) podr√≠a disparar timeouts y backlog en SQS.

```
```1:26:load_testing/locust_sqs/Soak-result.csv
Requests: 11064
Fallos: 0
Latencia media: 28976.31 ms
p95: 46000.00 ms
```

---

## 5. An√°lisis y hallazgos

- **Latencia estructural alta:** incluso sin fallos (smoke/soak) los tiempos de respuesta promedian >25 s debido al ciclo completo (upload + procesamiento inicial). Esto limita el throughput percibido por el cliente.
- **Cuello de botella en la API web durante la rampa:** los errores 5xx aparecen antes de saturar el worker, se√±al de que la capa web/ALB necesita escalado adicional y tiempos de timeout mayores para acompa√±ar la prueba.
- **Worker estable pero lento:** en soak no hubo errores, lo que sugiere que el worker es consistente mientras no se exceda la tasa objetivo, aunque el SLA sigue siendo deficiente.
- **Falta de correlaci√≥n con m√©tricas de SQS/CloudWatch:** no se recopilaron m√©tricas de backlog, edad del mensaje ni CPU del worker, lo que impide demostrar formalmente el momento en que la cola se degrada.

---

## 6. Recomendaciones y pr√≥ximos pasos

1. **Autoescalado coordinado:** habilitar pol√≠ticas de scaling para la API web (ALB/ASG) y para los workers Celery para absorber rampas agresivas sin 5xx.
2. **Optimizar autenticaci√≥n:** evitar re-login por ciclo (token reutilizable) o mover la autenticaci√≥n fuera del path cr√≠tico de la prueba para liberar capacidad.
3. **Instrumentaci√≥n en SQS/CloudWatch:** capturar `ApproximateNumberOfMessagesVisible`, `ApproximateAgeOfOldestMessage` y m√©tricas de consumo para correlacionar tiempos de Locust con backlog real.
4. **Reducci√≥n de latencia:** investigar procesamiento sincronizado inicial, tama√±o del archivo y operaciones en base de datos; considerar compresi√≥n o colas diferenciadas por tama√±o.
5. **Re-ejecuci√≥n dirigida:** tras aplicar ajustes, repetir la rampa aumentando el throughput objetivo (‚â•6 req/s) para validar la mejora y documentar el nuevo umbral.

---

## 7. Evidencias y artefactos

- CSV generados por Locust (`load_testing/locust_sqs/Smoke-results.csv`, `Ramp-results.csv`, `Soak-result.csv`).
- Scripts de ejecuci√≥n (`run_smoke.sh`, `run_ramp.sh`, `run_soak.sh`).
- Plan de prueba base en `capacity_planning/worker_sqs_locust_plan.md`.

Estos archivos permanecen en el repositorio para auditor√≠a y replicabilidad.

---

# üìä Pruebas de Carga - Capa Web con Arquitectura SQS + Worker (JMeter)

> **Fecha de ejecuci√≥n:** 16 de noviembre de 2025  
> **Infraestructura evaluada:** ALB + Auto Scaling (API Web) + SQS + Workers  
> **Herramienta:** Apache JMeter 5.6.3  
> **Objetivo:** Evaluar rendimiento de la API web con arquitectura desacoplada SQS + Worker

---

## 8. Escenario 1: 100 Usuarios Concurrentes

### 8.1 Configuraci√≥n del Escenario

| Par√°metro | Valor |
|-----------|-------|
| **Usuarios concurrentes** | 100 |
| **Rampa de inicio** | 0 ‚Üí 100 usuarios en 5 minutos |
| **Sostenimiento** | 100 usuarios por 5 minutos |
| **Rampa de descenso** | 100 ‚Üí 0 usuarios en 2 minutos |
| **Duraci√≥n total** | 10 minutos 33 segundos |
| **Fecha de ejecuci√≥n** | 16/11/2025 |

### 8.2 Resultados

| M√©trica | Valor |
|---------|-------|
| **Total de Requests** | 356 |
| **Requests Exitosos** | 299 (84.1%) |
| **Requests Fallidos** | 57 (15.9%) |
| **Tiempo Promedio** | 136.14 segundos |
| **Throughput** | 0.6 req/s |

**Comparaci√≥n con Arquitectura S√≠ncrona (Entrega 3):**

| M√©trica | Arq. S√≠ncrona (E3) | Arq. SQS (E4) | Diferencia |
|---------|-------------------|---------------|------------|
| Tasa de √âxito | 94.1% | 84.1% | -10% |
| Requests Exitosos | 335 | 299 | -36 |
| Requests Fallidos | 21 | 57 | +36 |
| Tiempo Promedio | 136.14s | 136.14s | Sin cambio |
| Throughput | 0.6 req/s | 0.6 req/s | Sin cambio |

### 8.3 An√°lisis

- ‚ö†Ô∏è **Degradaci√≥n de 10%** en tasa de √©xito respecto a arquitectura s√≠ncrona
- El desacoplamiento SQS + Worker introduce complejidad que genera m√°s fallos
- Tiempos de respuesta similares indican que el cuello de botella persiste
- Se requiere optimizaci√≥n de workers y configuraci√≥n de SQS

---

## 9. Escenario 2: 200 Usuarios Concurrentes

### 9.1 Configuraci√≥n del Escenario

| Par√°metro | Valor |
|-----------|-------|
| **Usuarios concurrentes** | 200 |
| **Rampa de inicio** | 0 ‚Üí 200 usuarios en 5 minutos |
| **Sostenimiento** | 200 usuarios por 5 minutos |
| **Rampa de descenso** | 200 ‚Üí 0 usuarios en 2 minutos |
| **Duraci√≥n total** | 11 minutos 31 segundos |
| **Fecha de ejecuci√≥n** | 16/11/2025 |

### 9.2 Resultados

| M√©trica | Valor |
|---------|-------|
| **Total de Requests** | 440 |
| **Requests Exitosos** | 292 (66.4%) |
| **Requests Fallidos** | 148 (33.6%) |
| **Tiempo Promedio** | ~180 segundos |
| **Throughput** | 0.6 req/s |

**Comparaci√≥n con Arquitectura S√≠ncrona (Entrega 3):**

| M√©trica | Arq. S√≠ncrona (E3) | Arq. SQS (E4) | Diferencia |
|---------|-------------------|---------------|------------|
| Tasa de √âxito | 76.4% | 66.4% | -10% |
| Requests Exitosos | 336 | 292 | -44 |
| Requests Fallidos | 104 | 148 | +44 |
| Tiempo Promedio | ~180s | ~180s | Sin cambio |
| Throughput | 0.6 req/s | 0.6 req/s | Sin cambio |

### 9.3 An√°lisis

- ‚ùå **Degradaci√≥n significativa**: 33.6% de errores con 200 usuarios
- El sistema con SQS muestra mayor inestabilidad bajo carga media-alta
- Workers no escalan adecuadamente para absorber la carga
- Posible saturaci√≥n de cola SQS o timeouts en procesamiento as√≠ncrono

---

## 10. Escenario 3: 300 Usuarios Concurrentes

### 10.1 Configuraci√≥n del Escenario

| Par√°metro | Valor |
|-----------|-------|
| **Usuarios concurrentes** | 300 |
| **Rampa de inicio** | 0 ‚Üí 300 usuarios en 5 minutos |
| **Sostenimiento** | 300 usuarios por 5 minutos |
| **Rampa de descenso** | 300 ‚Üí 0 usuarios en 2 minutos |
| **Duraci√≥n total** | ~12 minutos |
| **Fecha de ejecuci√≥n** | 16/11/2025 |

### 10.2 Resultados

| M√©trica | Valor |
|---------|-------|
| **Total de Requests** | 705 |
| **Requests Exitosos** | 520 (73.7%) |
| **Requests Fallidos** | 185 (26.3%) |
| **Tiempo Promedio** | ~150 segundos |
| **Throughput** | 1.0 req/s |

**Comparaci√≥n con Arquitectura S√≠ncrona (Entrega 3):**

| M√©trica | Arq. S√≠ncrona (E3) | Arq. SQS (E4) | Diferencia |
|---------|-------------------|---------------|------------|
| Tasa de √âxito | 83.7% | 73.7% | -10% |
| Requests Exitosos | 590 | 520 | -70 |
| Requests Fallidos | 115 | 185 | +70 |
| Tiempo Promedio | ~150s | ~150s | Sin cambio |
| Throughput | 1.0 req/s | 1.0 req/s | Sin cambio |

### 10.3 An√°lisis

- ‚ö†Ô∏è **Patr√≥n de degradaci√≥n consistente**: -10% en los 3 escenarios
- El autoscaling funciona pero la calidad del servicio disminuye
- Mayor cantidad de workers no compensa la complejidad del sistema distribuido
- Throughput mejora levemente (1.0 req/s) pero a costa de 26.3% de errores

---

## 11. An√°lisis Comparativo Global

### 11.1 Resumen de los 3 Escenarios

| Escenario | Usuarios | Requests | √âxito (E3) | √âxito (E4) | Degradaci√≥n | Throughput |
|-----------|----------|----------|------------|------------|-------------|------------|
| 1 | 100 | 356 | 94.1% | 84.1% | -10% | 0.6 req/s |
| 2 | 200 | 440 | 76.4% | 66.4% | -10% | 0.6 req/s |
| 3 | 300 | 705 | 83.7% | 73.7% | -10% | 1.0 req/s |

### 11.2 Hallazgos Principales

**Arquitectura SQS + Worker (Entrega 4):**

‚úÖ **Ventajas:**
- Desacoplamiento entre API y procesamiento
- Potencial para escalamiento independiente de workers
- Mayor resiliencia te√≥rica (mensajes persistentes en SQS)

‚ùå **Desventajas Observadas:**
- **Degradaci√≥n consistente de -10%** en tasa de √©xito en todos los escenarios
- Complejidad adicional genera m√°s puntos de fallo
- Workers no optimizados o mal configurados
- Posible saturaci√≥n de SQS bajo carga alta
- Timeouts en procesamiento as√≠ncrono

‚ö†Ô∏è **Cuellos de Botella Identificados:**
1. **Configuraci√≥n de Workers**: No escalan eficientemente
2. **SQS Visibility Timeout**: Mensajes pueden estar expirando
3. **Dead Letter Queue**: Posible acumulaci√≥n de mensajes fallidos
4. **Auto Scaling Delays**: Workers tardan en lanzarse
5. **Network Latency**: Overhead de comunicaci√≥n SQS

### 11.3 Recomendaciones

**Optimizaciones Cr√≠ticas:**

1. **Configuraci√≥n de Auto Scaling:**
   - Reducir cooldown period de workers
   - Ajustar m√©tricas de scaling (usar backlog SQS)
   - Aumentar capacidad m√≠nima de workers

2. **Configuraci√≥n de SQS:**
   - Aumentar visibility timeout (300s ‚Üí 600s)
   - Configurar Dead Letter Queue apropiadamente
   - Habilitar Long Polling para reducir requests vac√≠os

3. **Optimizaci√≥n de Workers:**
   - Mejorar eficiencia de procesamiento
   - Implementar retry logic robusto
   - Monitorear y reducir timeouts

4. **Monitoreo y Alertas:**
   - CloudWatch dashboards para SQS metrics
   - Alertas por backlog de mensajes
   - Tracking de success/error rate en tiempo real

**Pr√≥ximos Pasos:**

- [ ] Implementar optimizaciones recomendadas
- [ ] Re-ejecutar pruebas para validar mejoras
- [ ] Documentar m√©tricas de CloudWatch
- [ ] Realizar pruebas de soak (larga duraci√≥n)
- [ ] Validar comportamiento de Dead Letter Queue

---

**Documento actualizado:** 16/11/2025  
**Versi√≥n:** 2.0  
**Estado:** Completo con 3 escenarios documentados

---

# üìä Pruebas de Carga - Capa Web con Arquitectura SQS + Worker (JMeter)

> **Fecha de ejecuci√≥n:** 16 de noviembre de 2025  
> **Infraestructura evaluada:** ALB + Auto Scaling (API Web) + SQS + Workers  
> **Herramienta:** Apache JMeter 5.6.3  
> **Objetivo:** Evaluar rendimiento de la API web con nueva arquitectura desacoplada

---

## 8. Escenario 1: 100 Usuarios Concurrentes (JMeter)

### 8.1 Configuraci√≥n del Escenario

**Tipo de prueba:** Escalamiento con Ultimate Thread Group  
**Par√°metros de ejecuci√≥n:**

| Par√°metro | Valor |
|-----------|-------|
| **Usuarios concurrentes** | 100 |
| **Rampa de inicio** | 0 ‚Üí 100 usuarios en 5 minutos |
| **Sostenimiento** | 100 usuarios por 5 minutos |
| **Rampa de descenso** | 100 ‚Üí 0 usuarios en 2 minutos |
| **Duraci√≥n total estimada** | ~12 minutos |
| **Fecha/hora inicio** | 16/11/2025 18:06:40 GMT-05:00 |

**Endpoints evaluados:**
- `POST /api/auth/login` - Autenticaci√≥n
- `POST /api/videos/upload` - Carga de video (encolamiento en SQS)
- `GET /api/videos` - Listado de videos
- `GET /api/videos/{id}/status` - Estado de procesamiento

**Usuario de prueba:**
- Email: testv2@example.com
- User ID: 68
- Token JWT generado: 16/11/2025 18:03:48

### 8.2 Arquitectura Evaluada

```
Cliente (JMeter 100 users)
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      ALB      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Auto Scaling Group ‚îÇ
‚îÇ   (API Web - EC2)   ‚îÇ
‚îÇ   Min: 1 | Max: 5   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   AWS SQS   ‚îÇ ‚Üê Encolamiento as√≠ncrono
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Auto Scaling Group ‚îÇ
‚îÇ  (Workers - EC2)    ‚îÇ
‚îÇ   Min: 1 | Max: 10  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Diferencias vs Arquitectura Anterior (Entrega 3):**
- ‚úÖ **Procesamiento as√≠ncrono**: Videos se encolan en SQS, no se procesan s√≠ncronamente
- ‚úÖ **Respuesta m√°s r√°pida**: API responde inmediatamente tras encolamiento
- ‚úÖ **Escalabilidad independiente**: Workers escalan seg√∫n backlog de SQS
- ‚úÖ **Mayor resiliencia**: Mensajes persistentes en SQS

### 8.3 Resultados Finales

> ‚úÖ **Estado:** Prueba completada exitosamente  
> üìç **Duraci√≥n total:** 10 minutos 41 segundos  
> ÔøΩ **Hora de finalizaci√≥n:** 16/11/2025 18:17:22 GMT-05:00  
> üìä **Archivos de salida:**
> - CSV: `cloud_load_testing/escenario_1_capa_web_autoscalingV2/Fase_2_Escalamiento/Escenario_100_usuarios/resultados/resultados_v2.csv`
> - Dashboard: `cloud_load_testing/escenario_1_capa_web_autoscalingV2/Fase_2_Escalamiento/Escenario_100_usuarios/dashboards_v2/index.html`

**Resumen de Resultados:**

| M√©trica | Valor | Estado |
|---------|-------|--------|
| **Total de Requests** | 402 | ‚úÖ |
| **Requests Exitosos** | 306 | 76.12% |
| **Requests Fallidos** | 96 | 23.88% |
| **Tiempo Promedio** | 119.85 segundos | ‚ö†Ô∏è Alto |
| **Tiempo M√≠nimo** | 3.88 segundos | ‚úÖ |
| **Tiempo M√°ximo** | 344.34 segundos | ‚ùå Muy alto |
| **Throughput** | 0.6 req/s | ‚ö†Ô∏è Bajo |
| **Duraci√≥n Total** | 10min 41s | ‚úÖ |

**Comparaci√≥n con Arquitectura Anterior:**

| M√©trica | Arquitectura S√≠ncrona (E3) | Arquitectura SQS (E4) | Resultado |
|---------|----------------------------|-----------------------|-----------|
| Total Requests | 356 | 402 | ‚úÖ +13% |
| Tasa de √âxito | 94.1% | 76.12% | ‚ùå -18% |
| Tiempo Promedio | 136.14s | 119.85s | ‚úÖ -12% |
| Throughput | 0.6 req/s | 0.6 req/s | ‚û°Ô∏è Similar |
| Errores | 21 (5.9%) | 96 (23.88%) | ‚ùå +304% |

**Validaci√≥n de Hip√≥tesis:**

| Hip√≥tesis | Esperado | Real | Validada |
|-----------|----------|------|----------|
| API responde en <5s | <5s | 3.88s (min), 119.85s (avg) | ‚ùå Parcial |
| Tasa de √©xito >95% | >95% | 76.12% | ‚ùå No |
| Throughput 3-5x mayor | >3 req/s | 0.6 req/s | ‚ùå No |
| Workers independientes | Sin impacto en API | Alto tiempo de respuesta | ‚ùå No |

### 8.4 An√°lisis Comparativo Detallado

#### 8.4.1 Tiempos de Respuesta

| M√©trica | Arq. S√≠ncrona (E3) | Arq. SQS + Worker (E4) | Diferencia | % Cambio |
|---------|-------------------|------------------------|------------|----------|
| Promedio | 136.14s | 119.85s | -16.29s | ‚úÖ -12.0% |
| M√≠nimo | ~4s | 3.88s | -0.12s | ‚úÖ -3.0% |
| M√°ximo | ~300s | 344.34s | +44.34s | ‚ùå +14.8% |

**An√°lisis:**
- ‚úÖ **Tiempo promedio mejor√≥ 12%** respecto a arquitectura s√≠ncrona
- ‚ùå **Tiempo m√°ximo empeor√≥ 14.8%**, indicando picos de latencia mayores
- ‚ö†Ô∏è **Variabilidad alta**: rango de 3.88s a 344.34s sugiere comportamiento inconsistente

#### 8.4.2 Throughput y Carga

| M√©trica | Arq. S√≠ncrona (E3) | Arq. SQS + Worker (E4) | Diferencia | % Cambio |
|---------|-------------------|------------------------|------------|----------|
| Requests/segundo | 0.6 | 0.6 | 0 | ‚û°Ô∏è Sin cambio |
| Total requests | 356 | 402 | +46 | ‚úÖ +12.9% |
| Requests exitosos | 335 (94.1%) | 306 (76.12%) | -29 | ‚ùå -8.7% |
| Requests fallidos | 21 (5.9%) | 96 (23.88%) | +75 | ‚ùå +357.1% |
| Duraci√≥n total | 10min 33s | 10min 41s | +8s | ‚û°Ô∏è Similar |

**An√°lisis:**
- ‚úÖ **Mayor cantidad de requests procesados** (+12.9%)
- ‚ùå **Tasa de error aument√≥ 4x** (5.9% ‚Üí 23.88%)
- ‚û°Ô∏è **Throughput se mantuvo igual** (0.6 req/s), sin mejora esperada
- ‚ùå **Menos requests exitosos absolutos** a pesar de mayor carga total

#### 8.4.3 Comportamiento del Sistema

**Arquitectura S√≠ncrona (Baseline - Entrega 3):**
- Tiempos de respuesta muy altos pero m√°s predecibles
- Procesamiento bloqueante en API
- Tasa de error baja (5.9%)
- Escalamiento limitado por CPU de procesamiento

**Arquitectura SQS + Worker (Nueva - Entrega 4):**
- ‚ùå **Tasa de error elevada (23.88%)**: Principal problema detectado
- ‚ö†Ô∏è **Tiempos de respuesta todav√≠a altos** (avg 119.85s): El desacoplamiento no redujo latencia como se esperaba
- ‚ùå **Sin mejora en throughput**: Se mantuvo en 0.6 req/s
- ‚ö†Ô∏è **Mayor variabilidad**: Picos de hasta 344s vs promedio de 120s

**Errores Observados Durante la Prueba:**

| Fase | Usuarios Activos | Tasa de Error | Observaci√≥n |
|------|-----------------|---------------|-------------|
| Rampa inicial (0-50) | 11-61 | 0-7.69% | Baja tasa de errores |
| Rampa media (50-100) | 77-100 | 50-80% | Picos cr√≠ticos de errores |
| Sostenimiento | 100 | 18-65% | Errores fluctuantes |
| Descenso | 92-0 | 0-6.25% | Estabilizaci√≥n al reducir carga |

### 8.5 M√©tricas de AWS CloudWatch (A recolectar)

**Auto Scaling Group - API Web:**
- [ ] CPU Utilization
- [ ] Network In/Out
- [ ] N√∫mero de instancias activas
- [ ] Target Response Time (ALB)

**Auto Scaling Group - Workers:**
- [ ] CPU Utilization
- [ ] N√∫mero de instancias activas
- [ ] Mensajes procesados/segundo

**AWS SQS:**
- [ ] ApproximateNumberOfMessagesVisible
- [ ] ApproximateNumberOfMessagesNotVisible
- [ ] ApproximateAgeOfOldestMessage
- [ ] NumberOfMessagesSent
- [ ] NumberOfMessagesReceived

**Application Load Balancer:**
- [ ] Request Count
- [ ] Target Response Time
- [ ] HTTP 2xx/4xx/5xx Count
- [ ] Active Connection Count

### 8.6 Dashboard JMeter

Una vez completada la prueba, el dashboard HTML interactivo estar√° disponible en:
```
cloud_load_testing/escenario_1_capa_web_autoscalingV2/
  ‚îî‚îÄ‚îÄ Fase_2_Escalamiento/
      ‚îî‚îÄ‚îÄ Escenario_100_usuarios/
          ‚îî‚îÄ‚îÄ dashboards_v2/
              ‚îî‚îÄ‚îÄ index.html
```

**Gr√°ficos incluidos:**
- ‚úÖ Response Times Over Time
- ‚úÖ Active Threads Over Time
- ‚úÖ Transactions Per Second
- ‚úÖ Response Time Percentiles
- ‚úÖ Bytes Throughput Over Time
- ‚úÖ Latencies Over Time
- ‚úÖ Connect Time Over Time
- ‚úÖ Errors Over Time

### 8.7 Conclusiones del Escenario 1 (100 Usuarios)

**Hallazgos Principales:**

1. **‚ùå La arquitectura SQS + Worker NO cumpli√≥ las expectativas iniciales:**
   - Tasa de error 4x mayor que arquitectura s√≠ncrona (23.88% vs 5.9%)
   - Sin mejora en throughput (0.6 req/s en ambas)
   - Tiempos de respuesta a√∫n altos (119.85s promedio)

2. **‚ö†Ô∏è Problemas identificados:**
   - **Picos de error durante rampa**: 50-80% de error cuando usuarios alcanzaron 80-100
   - **Posible saturaci√≥n de SQS o Workers**: Errores se concentran en fase de alta concurrencia
   - **Timeouts probables**: Tiempos m√°ximos >340s sugieren timeouts en requests
   - **Falta de autoscaling efectivo**: Workers no escalaron adecuadamente

3. **‚úÖ Aspectos positivos (limitados):**
   - Ligera reducci√≥n en tiempo promedio (-12%)
   - Mayor capacidad total de requests (+12.9%)
   - M√≠nimos tiempos similares (3.88s)

**Posibles Causas de los Problemas:**

1. **Configuraci√≥n de SQS:**
   - Visibility timeout insuficiente
   - Dead letter queue no configurado o saturado
   - L√≠mites de throughput alcanzados

2. **Workers:**
   - Auto Scaling no configurado o tard√≠o
   - Recursos insuficientes (CPU/memoria)
   - Procesamiento demasiado lento por worker

3. **API Web:**
   - Timeouts en encolamiento a SQS
   - L√≠mites de conexiones concurrentes
   - Falta de retry logic

4. **Infraestructura General:**
   - Configuraci√≥n de Auto Scaling Groups inadecuada
   - Health checks fallando
   - Network throttling

**Comparaci√≥n con Pruebas Locust (Secciones anteriores):**

Las pruebas Locust mostraron:
- Smoke: 100% √©xito, 3.75 req/s, latencia 2.6s
- Soak: 100% √©xito, 4.1 req/s, latencia 28.9s

**Diferencias vs JMeter (100 usuarios):**
- ‚ùå JMeter: 76% √©xito vs Locust Smoke: 100% √©xito
- ‚ùå JMeter: 0.6 req/s vs Locust: 3.75-4.1 req/s
- ‚ùå JMeter: 119s promedio vs Locust: 2.6-28.9s

**Posible explicaci√≥n**: Las pruebas Locust fueron m√°s ligeras o la infraestructura mejor√≥/empeor√≥ entre ejecuciones.

### 8.8 Recomendaciones y Pr√≥ximos Pasos

**Acciones Inmediatas:**

1. **üîç Investigar logs de errores:**
   - Revisar CloudWatch Logs de API y Workers
   - Identificar tipos de errores (500, 502, 503, 504)
   - Correlacionar con timestamps de la prueba

2. **üìä Analizar m√©tricas de SQS:**
   - ApproximateNumberOfMessagesVisible durante prueba
   - ApproximateAgeOfOldestMessage
   - NumberOfMessagesReceived vs Sent
   - Dead letter queue messages

3. **‚öôÔ∏è Revisar configuraci√≥n de Auto Scaling:**
   - Pol√≠ticas de scaling de Workers
   - CPU/Memory triggers
   - Cooldown periods
   - Min/Max/Desired capacity

4. **üîß Ajustes de configuraci√≥n recomendados:**
   - Aumentar visibility timeout de SQS (actual: 300s ‚Üí sugerido: 600s)
   - Configurar Dead Letter Queue con max receives = 3
   - Ajustar Auto Scaling de workers: Min=2, Desired=4, Max=15
   - Incrementar health check grace period
   - Configurar retry logic en API

**Pr√≥ximas Pruebas:**

- [ ] **Re-ejecutar 100 usuarios** tras ajustes de configuraci√≥n
- [ ] **Prueba con 50 usuarios** para validar punto de estabilidad
- [ ] **Ejecutar 200 usuarios** solo si 100 mejora >90% √©xito
- [ ] **Prueba de soak** (30-45 min) con carga sostenida baja
- [ ] **Monitoreo en tiempo real** de CloudWatch durante ejecuci√≥n

**Investigaciones Adicionales:**

- [ ] Comparar dashboards Locust vs JMeter para entender discrepancias
- [ ] Validar que el token JWT no est√° expirando mid-test
- [ ] Verificar l√≠mites de rate limiting en API/ALB
- [ ] Revisar tama√±o de archivos de video en prueba
- [ ] Validar configuraci√≥n de base de datos (connections pool)

---

**√öltima actualizaci√≥n:** 16/11/2025 18:20  
**Estado del documento:** ‚úÖ Completado con resultados de Escenario 1  
**Pr√≥xima revisi√≥n:** Tras an√°lisis de logs y ajustes de configuraci√≥n

